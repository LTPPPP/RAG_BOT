{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain chromadb python-dotenv sentence-transformers langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Update the TextLoader to specify the encoding\n",
    "loader = TextLoader('dataset.txt', encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=4)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# The rest of your code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Define Index Name\n",
    "index_name = \"infinity-demo\"\n",
    "\n",
    "# Ensure the persist directory exists and has write permissions\n",
    "persist_directory = \"./chroma_data\" \n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "\n",
    "# Check if the directory has write permissions\n",
    "if not os.access(persist_directory, os.W_OK):\n",
    "    raise PermissionError(f\"The directory {persist_directory} is not writable.\")\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = Client(Settings(persist_directory=persist_directory))\n",
    "\n",
    "\n",
    "\n",
    "# Check if the collection already exists\n",
    "existing_collections = [collection.name for collection in chroma_client.list_collections()]\n",
    "\n",
    "if index_name not in existing_collections:\n",
    "    # Create new collection and add documents\n",
    "    docsearch = Chroma.from_documents(documents=docs, embedding=embeddings, collection_name=index_name, persist_directory=persist_directory)\n",
    "else:\n",
    "    # Load the existing collection\n",
    "    docsearch = Chroma(collection_name=index_name, persist_directory=persist_directory)\n",
    "\n",
    "# Persist the index to disk\n",
    "docsearch.persist()\n",
    "\n",
    "print(f\"Index '{index_name}' created and persisted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Define the repo ID and connect to Mixtral model on Huggingface\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "api_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "llm = HuggingFaceHub(\n",
    "  repo_id=repo_id, \n",
    "  model_kwargs={\"temperature\": 0.8, \"top_k\": 50, \"top_p\": 0.95, \"max_length\": 1000}, \n",
    "  huggingfacehub_api_token=api_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a fortune teller. These Human will ask you a questions about their life. \n",
    "Use following piece of context to answer the question. \n",
    "If you don't know the answer, just say you don't know. \n",
    "Keep the answer within 3 sentences and concise.\n",
    "The answer can be up to 1000 words. If the enough 3 sentences then stop. \n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template, \n",
    "  input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load env\n",
    "from dotenv import load_dotenv\n",
    "class ChatBot():\n",
    "  load_dotenv()\n",
    "\n",
    "  # The rest of the code here\n",
    "  print(docsearch.as_retriever())\n",
    "\n",
    "  rag_chain = (\n",
    "    {\"context\": docsearch.as_retriever(),  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside ChatBot() class\n",
    "bot = ChatBot()\n",
    "input = \"nguyên nhân bệnh tử kỷ là gì\" # convert to vector\n",
    "result = bot.rag_chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
